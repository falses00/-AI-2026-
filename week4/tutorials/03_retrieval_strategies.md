# ğŸ¯ æ£€ç´¢ç­–ç•¥è¯¦è§£

> **å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡è¯­ä¹‰æ£€ç´¢çš„æ ¸å¿ƒç­–ç•¥å’Œä¼˜åŒ–æŠ€å·§

---

## 1. æ£€ç´¢çš„é‡è¦æ€§

RAGç³»ç»Ÿçš„æ•ˆæœ = æ£€ç´¢è´¨é‡ Ã— ç”Ÿæˆè´¨é‡

**å¦‚æœæ£€ç´¢ä¸åˆ°ç›¸å…³æ–‡æ¡£ï¼ŒLLMå†å¼ºä¹Ÿæ— æ³•ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆï¼**

---

## 2. Top-Kæ£€ç´¢

### 2.1 åŸºç¡€Top-K

```python
def basic_topk_search(collection, query: str, k: int = 5):
    """åŸºç¡€Top-Kæ£€ç´¢"""
    results = collection.query(
        query_texts=[query],
        n_results=k
    )
    return results["documents"][0]

# ä½¿ç”¨
docs = basic_topk_search(collection, "Python Webæ¡†æ¶", k=3)
```

### 2.2 Kå€¼é€‰æ‹©

| Kå€¼ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|-----|------|------|
| å° (1-3) | ç²¾ç¡®ï¼Œçœtoken | å¯èƒ½é—æ¼ |
| ä¸­ (5-10) | å¹³è¡¡ | é€‚ä¸­ |
| å¤§ (15+) | è¦†ç›–å…¨ | å™ªéŸ³å¤šï¼Œè´¹token |

**å»ºè®®**ï¼šå…ˆæ£€ç´¢è¾ƒå¤š(10-20)ï¼Œå†ç”¨é‡æ’åºç­›é€‰ã€‚

---

## 3. ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤

### 3.1 è·ç¦»é˜ˆå€¼

```python
def search_with_threshold(collection, query: str, threshold: float = 0.5):
    """å¸¦é˜ˆå€¼çš„æ£€ç´¢"""
    results = collection.query(
        query_texts=[query],
        n_results=20,  # å…ˆå–å¤šä¸€äº›
        include=["documents", "distances"]
    )
    
    # è¿‡æ»¤æ‰è·ç¦»å¤ªå¤§çš„ï¼ˆç›¸ä¼¼åº¦å¤ªä½ï¼‰
    filtered = []
    for doc, dist in zip(results["documents"][0], results["distances"][0]):
        if dist < threshold:
            filtered.append({"doc": doc, "distance": dist})
    
    return filtered

# ä½™å¼¦è·ç¦»: 0=å®Œå…¨ç›¸åŒ, 2=å®Œå…¨ç›¸å
# å»ºè®®é˜ˆå€¼: 0.3-0.7
```

### 3.2 åŠ¨æ€é˜ˆå€¼

```python
def dynamic_threshold_search(collection, query: str, min_results: int = 3):
    """åŠ¨æ€è°ƒæ•´é˜ˆå€¼ç¡®ä¿æœ‰è¶³å¤Ÿç»“æœ"""
    thresholds = [0.3, 0.5, 0.7, 1.0]
    
    for threshold in thresholds:
        results = search_with_threshold(collection, query, threshold)
        if len(results) >= min_results:
            return results
    
    return results  # è¿”å›æœ€åçš„ç»“æœ
```

---

## 4. å…ƒæ•°æ®è¿‡æ»¤

### 4.1 é¢„è¿‡æ»¤ï¼ˆæ¨èï¼‰

```python
def filtered_search(collection, query: str, filters: dict):
    """å…ˆè¿‡æ»¤å†æœç´¢"""
    results = collection.query(
        query_texts=[query],
        n_results=10,
        where=filters  # å…ƒæ•°æ®è¿‡æ»¤
    )
    return results

# ä½¿ç”¨
results = filtered_search(
    collection,
    query="Pythonæ¡†æ¶",
    filters={"category": "web", "year": {"$gte": 2020}}
)
```

### 4.2 å¤æ‚æ¡ä»¶

```python
# ANDæ¡ä»¶
where={
    "$and": [
        {"category": "tech"},
        {"language": "python"}
    ]
}

# ORæ¡ä»¶
where={
    "$or": [
        {"category": "web"},
        {"category": "api"}
    ]
}

# èŒƒå›´æ¡ä»¶
where={
    "year": {"$gte": 2020, "$lte": 2024}
}

# åŒ…å«æ¡ä»¶
where={
    "tags": {"$in": ["fastapi", "flask", "django"]}
}
```

---

## 5. æŸ¥è¯¢æ‰©å±•

### 5.1 åŒä¹‰è¯æ‰©å±•

```python
def expand_query_synonyms(query: str, synonyms: dict) -> list[str]:
    """ä½¿ç”¨åŒä¹‰è¯æ‰©å±•æŸ¥è¯¢"""
    queries = [query]
    
    for word, syns in synonyms.items():
        if word in query:
            for syn in syns:
                queries.append(query.replace(word, syn))
    
    return queries

# ä½¿ç”¨
synonyms = {
    "API": ["æ¥å£", "æœåŠ¡ç«¯ç‚¹"],
    "æ¡†æ¶": ["framework", "åº“"],
    "é«˜æ€§èƒ½": ["å¿«é€Ÿ", "é«˜æ•ˆ"]
}

queries = expand_query_synonyms("é«˜æ€§èƒ½APIæ¡†æ¶", synonyms)
# ["é«˜æ€§èƒ½APIæ¡†æ¶", "å¿«é€ŸAPIæ¡†æ¶", "é«˜æ€§èƒ½æ¥å£æ¡†æ¶", ...]
```

### 5.2 LLMæŸ¥è¯¢æ”¹å†™

```python
async def rewrite_query(client, query: str) -> list[str]:
    """ä½¿ç”¨LLMæ”¹å†™æŸ¥è¯¢"""
    response = await client.chat.completions.create(
        model="deepseek-chat",
        messages=[{
            "role": "user",
            "content": f"""è¯·å°†ä»¥ä¸‹æœç´¢æŸ¥è¯¢æ”¹å†™æˆ3ä¸ªä¸åŒçš„è¡¨è¾¾æ–¹å¼ï¼Œä¿æŒè¯­ä¹‰ç›¸åŒï¼š

æŸ¥è¯¢ï¼š{query}

è¯·ç›´æ¥è¾“å‡º3ä¸ªæ”¹å†™åçš„æŸ¥è¯¢ï¼Œæ¯è¡Œä¸€ä¸ªï¼š"""
        }],
        temperature=0.7
    )
    
    rewrites = response.choices[0].message.content.strip().split("\n")
    return [query] + rewrites[:3]

# ä½¿ç”¨
queries = await rewrite_query(client, "Python Webå¼€å‘")
# ["Python Webå¼€å‘", "ä½¿ç”¨Pythonè¿›è¡Œç½‘ç«™å¼€å‘", "Pythonåç«¯å¼€å‘æ¡†æ¶", ...]
```

### 5.3 å¤šæŸ¥è¯¢èåˆ

```python
def multi_query_search(collection, queries: list[str], top_k: int = 5):
    """å¤šæŸ¥è¯¢æœç´¢å¹¶èåˆç»“æœ"""
    all_results = {}
    
    for query in queries:
        results = collection.query(
            query_texts=[query],
            n_results=top_k,
            include=["documents", "distances"]
        )
        
        for doc, dist in zip(results["documents"][0], results["distances"][0]):
            if doc not in all_results:
                all_results[doc] = []
            all_results[doc].append(dist)
    
    # è®¡ç®—å¹³å‡è·ç¦»
    ranked = []
    for doc, distances in all_results.items():
        avg_dist = sum(distances) / len(distances)
        ranked.append({"doc": doc, "avg_distance": avg_dist, "count": len(distances)})
    
    # æŒ‰å¹³å‡è·ç¦»æ’åº
    ranked.sort(key=lambda x: x["avg_distance"])
    return ranked[:top_k]
```

---

## 6. åˆ†å—æ£€ç´¢ç­–ç•¥

### 6.1 å›ºå®šå¤§å°åˆ†å—

```python
def chunk_fixed(text: str, size: int = 500, overlap: int = 50) -> list[str]:
    """å›ºå®šå¤§å°åˆ†å—"""
    chunks = []
    start = 0
    while start < len(text):
        end = min(start + size, len(text))
        chunks.append(text[start:end])
        start = end - overlap
    return chunks
```

### 6.2 è¯­ä¹‰åˆ†å—ï¼ˆæŒ‰æ®µè½/ç« èŠ‚ï¼‰

```python
def chunk_by_paragraph(text: str) -> list[str]:
    """æŒ‰æ®µè½åˆ†å—"""
    paragraphs = text.split("\n\n")
    return [p.strip() for p in paragraphs if p.strip()]

def chunk_by_heading(text: str) -> list[str]:
    """æŒ‰æ ‡é¢˜åˆ†å—ï¼ˆMarkdownï¼‰"""
    import re
    sections = re.split(r'\n#{1,3}\s+', text)
    return [s.strip() for s in sections if s.strip()]
```

### 6.3 æ£€ç´¢æ—¶çš„ä¸Šä¸‹æ–‡æ‰©å±•

```python
def search_with_context(collection, query: str, context_size: int = 1):
    """æ£€ç´¢å¹¶è¿”å›ç›¸é‚»chunks"""
    results = collection.query(
        query_texts=[query],
        n_results=5,
        include=["documents", "metadatas"]
    )
    
    expanded = []
    for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
        chunk_idx = meta.get("chunk_index", 0)
        source = meta.get("source", "")
        
        # è·å–ç›¸é‚»chunks
        neighbors = collection.get(
            where={
                "$and": [
                    {"source": source},
                    {"chunk_index": {"$gte": chunk_idx - context_size}},
                    {"chunk_index": {"$lte": chunk_idx + context_size}}
                ]
            }
        )
        
        # åˆå¹¶æ–‡æœ¬
        combined = " ".join(neighbors["documents"])
        expanded.append(combined)
    
    return expanded
```

---

## 7. å®Œæ•´æ£€ç´¢Pipeline

```python
class SmartRetriever:
    def __init__(self, collection, client):
        self.collection = collection
        self.client = client
    
    async def retrieve(
        self, 
        query: str, 
        top_k: int = 5,
        filters: dict = None,
        expand_query: bool = True,
        threshold: float = 0.7
    ) -> list[dict]:
        """æ™ºèƒ½æ£€ç´¢Pipeline"""
        
        # 1. æŸ¥è¯¢æ‰©å±•
        if expand_query:
            queries = await self._expand_query(query)
        else:
            queries = [query]
        
        # 2. å¤šæŸ¥è¯¢æ£€ç´¢
        all_results = []
        for q in queries:
            results = self.collection.query(
                query_texts=[q],
                n_results=top_k * 2,
                where=filters,
                include=["documents", "distances", "metadatas"]
            )
            all_results.append(results)
        
        # 3. èåˆå»é‡
        merged = self._merge_results(all_results)
        
        # 4. é˜ˆå€¼è¿‡æ»¤
        filtered = [r for r in merged if r["distance"] < threshold]
        
        # 5. è¿”å›Top-K
        return filtered[:top_k]
    
    async def _expand_query(self, query: str) -> list[str]:
        # å®ç°æŸ¥è¯¢æ‰©å±•...
        return [query]
    
    def _merge_results(self, results_list) -> list[dict]:
        # å®ç°ç»“æœèåˆ...
        merged = {}
        for results in results_list:
            for doc, dist, meta in zip(
                results["documents"][0],
                results["distances"][0],
                results["metadatas"][0]
            ):
                if doc not in merged or dist < merged[doc]["distance"]:
                    merged[doc] = {"doc": doc, "distance": dist, "metadata": meta}
        
        return sorted(merged.values(), key=lambda x: x["distance"])
```

---

## ğŸ“º æ¨èBç«™è§†é¢‘

æœç´¢ï¼š
- **"RAG æ£€ç´¢ä¼˜åŒ–"**
- **"å‘é‡æ£€ç´¢ ç­–ç•¥"**
- **"è¯­ä¹‰æœç´¢ å®æˆ˜"**

---

## 8. ç»§ç»­å­¦ä¹ 

ğŸ“Œ **Week 4 å­¦ä¹ é¡ºåº**ï¼š
1. âœ… Embeddingå‘é‡åŒ–å…¥é—¨
2. âœ… ChromaDBæˆ–Milvus
3. âœ… æ£€ç´¢ç­–ç•¥è¯¦è§£ï¼ˆæœ¬æ•™ç¨‹ï¼‰
4. â¡ï¸ æ„å»ºç®€å•RAGç³»ç»Ÿ

---

**å¥½çš„æ£€ç´¢ç­–ç•¥æ˜¯RAGæˆåŠŸçš„ä¸€åŠï¼ğŸ’ª**
