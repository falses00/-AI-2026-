# ğŸ”— ä½¿ç”¨LangChainæ„å»ºæ··åˆæ£€ç´¢

> **å­¦ä¹ ç›®æ ‡**ï¼šä½¿ç”¨LangChainæ¡†æ¶å¿«é€Ÿå®ç°æ··åˆæ£€ç´¢

---

## 1. LangChainç®€ä»‹

**LangChain**æ˜¯æ„å»ºLLMåº”ç”¨çš„æµè¡Œæ¡†æ¶ï¼Œæä¾›äº†ä¸°å¯Œçš„æ£€ç´¢ç»„ä»¶ã€‚

---

## 2. å®‰è£…ä¾èµ–

```bash
pip install langchain langchain-openai langchain-community chromadb rank-bm25
```

---

## 3. LangChainæ£€ç´¢å™¨

### 3.1 å‘é‡æ£€ç´¢å™¨

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.schema import Document

# åˆ›å»ºembedding
embeddings = OpenAIEmbeddings(
    openai_api_key="your-key",
    openai_api_base="https://api.deepseek.com/v1"
)

# åˆ›å»ºæ–‡æ¡£
docs = [
    Document(page_content="FastAPIæ˜¯é«˜æ€§èƒ½Pythonæ¡†æ¶", metadata={"source": "web"}),
    Document(page_content="Djangoæ˜¯å…¨åŠŸèƒ½Webæ¡†æ¶", metadata={"source": "web"}),
    Document(page_content="å‘é‡æ•°æ®åº“å­˜å‚¨embedding", metadata={"source": "db"}),
]

# åˆ›å»ºå‘é‡å­˜å‚¨
vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=embeddings,
    persist_directory="./langchain_db"
)

# åˆ›å»ºæ£€ç´¢å™¨
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}
)

# æ£€ç´¢
results = retriever.invoke("Python Webå¼€å‘")
for doc in results:
    print(doc.page_content)
```

### 3.2 BM25æ£€ç´¢å™¨

```python
from langchain_community.retrievers import BM25Retriever

# åˆ›å»ºBM25æ£€ç´¢å™¨
bm25_retriever = BM25Retriever.from_documents(docs)
bm25_retriever.k = 3

# æ£€ç´¢
results = bm25_retriever.invoke("Pythonæ¡†æ¶")
for doc in results:
    print(doc.page_content)
```

---

## 4. æ··åˆæ£€ç´¢å™¨

### 4.1 EnsembleRetriever

```python
from langchain.retrievers import EnsembleRetriever

# åˆ›å»ºå‘é‡æ£€ç´¢å™¨
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# åˆ›å»ºBM25æ£€ç´¢å™¨
bm25_retriever = BM25Retriever.from_documents(docs, k=5)

# åˆ›å»ºæ··åˆæ£€ç´¢å™¨ï¼ˆRRFèåˆï¼‰
ensemble_retriever = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.6, 0.4]  # è¯­ä¹‰:å…³é”®è¯ = 6:4
)

# æ£€ç´¢
results = ensemble_retriever.invoke("é«˜æ€§èƒ½APIå¼€å‘")
for doc in results:
    print(f"- {doc.page_content}")
```

### 4.2 è‡ªå®šä¹‰æƒé‡

```python
# æ›´ä¾§é‡è¯­ä¹‰
semantic_heavy = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.8, 0.2]
)

# æ›´ä¾§é‡å…³é”®è¯
keyword_heavy = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.3, 0.7]
)
```

---

## 5. å®Œæ•´RAG withæ··åˆæ£€ç´¢

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain.schema import Document

# 1. å‡†å¤‡æ–‡æ¡£
documents = [
    Document(page_content="FastAPIæ˜¯ä¸€ä¸ªç°ä»£ã€å¿«é€Ÿçš„Python Webæ¡†æ¶ï¼Œæ€§èƒ½ä¸Goå’ŒNode.jsç›¸å½“ã€‚"),
    Document(page_content="FastAPIä½¿ç”¨Pydanticè¿›è¡Œæ•°æ®éªŒè¯ï¼Œè‡ªåŠ¨ç”ŸæˆOpenAPIæ–‡æ¡£ã€‚"),
    Document(page_content="Djangoæ˜¯Pythonçš„å…¨åŠŸèƒ½Webæ¡†æ¶ï¼Œé€‚åˆå¤§å‹é¡¹ç›®ã€‚"),
    Document(page_content="Flaskæ˜¯è½»é‡çº§Pythonå¾®æ¡†æ¶ï¼Œçµæ´»ä½†åŠŸèƒ½è¾ƒå°‘ã€‚"),
    Document(page_content="å‘é‡æ•°æ®åº“å¦‚ChromaDBç”¨äºå­˜å‚¨å’Œæ£€ç´¢æ–‡æœ¬embeddingã€‚")
]

# 2. åˆ›å»ºæ£€ç´¢å™¨
embeddings = OpenAIEmbeddings(
    openai_api_key="your-key",
    openai_api_base="https://api.deepseek.com/v1"
)

vectorstore = Chroma.from_documents(documents, embeddings)
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

bm25_retriever = BM25Retriever.from_documents(documents, k=3)

# æ··åˆæ£€ç´¢å™¨
hybrid_retriever = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.6, 0.4]
)

# 3. åˆ›å»ºLLM
llm = ChatOpenAI(
    model="deepseek-chat",
    openai_api_key="your-key",
    openai_api_base="https://api.deepseek.com/v1"
)

# 4. åˆ›å»ºPrompt
prompt = ChatPromptTemplate.from_template("""
åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·ç®€æ´å‡†ç¡®åœ°å›ç­”ï¼š
""")

# 5. æ„å»ºRAG Chain (LCELè¯­æ³•)
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

rag_chain = (
    {"context": hybrid_retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# 6. ä½¿ç”¨
answer = rag_chain.invoke("FastAPIæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ")
print(answer)
```

---

## 6. å¤šæŸ¥è¯¢æ£€ç´¢å™¨

```python
from langchain.retrievers import MultiQueryRetriever

# è‡ªåŠ¨ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“
multi_query_retriever = MultiQueryRetriever.from_llm(
    retriever=hybrid_retriever,
    llm=llm
)

# æ£€ç´¢ï¼ˆä¼šè‡ªåŠ¨ç”Ÿæˆå¤šä¸ªç›¸å…³æŸ¥è¯¢ï¼‰
results = multi_query_retriever.invoke("Python Webæ¡†æ¶å¯¹æ¯”")
```

---

## 7. ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor

# åˆ›å»ºå‹ç¼©å™¨
compressor = LLMChainExtractor.from_llm(llm)

# åˆ›å»ºå‹ç¼©æ£€ç´¢å™¨
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=hybrid_retriever
)

# æ£€ç´¢ï¼ˆä¼šè‡ªåŠ¨æå–ç›¸å…³å†…å®¹ï¼‰
results = compression_retriever.invoke("FastAPIæ€§èƒ½å¦‚ä½•ï¼Ÿ")
for doc in results:
    print(doc.page_content)
```

---

## 8. å®Œæ•´ç¤ºä¾‹ï¼šçŸ¥è¯†åº“é—®ç­”

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

class LangChainRAG:
    def __init__(self, docs_path: str = "./knowledge"):
        # åŠ è½½æ–‡æ¡£
        loader = DirectoryLoader(docs_path, glob="**/*.md", loader_cls=TextLoader)
        documents = loader.load()
        
        # åˆ†å—
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        splits = splitter.split_documents(documents)
        
        # åˆ›å»ºæ£€ç´¢å™¨
        embeddings = OpenAIEmbeddings(
            openai_api_key="your-key",
            openai_api_base="https://api.deepseek.com/v1"
        )
        
        vectorstore = Chroma.from_documents(splits, embeddings)
        vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
        bm25_retriever = BM25Retriever.from_documents(splits, k=5)
        
        self.retriever = EnsembleRetriever(
            retrievers=[vector_retriever, bm25_retriever],
            weights=[0.6, 0.4]
        )
        
        # åˆ›å»ºLLM
        self.llm = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key="your-key",
            openai_api_base="https://api.deepseek.com/v1"
        )
        
        # åˆ›å»ºå¯¹è¯è®°å¿†
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        # åˆ›å»ºå¯¹è¯é“¾
        self.chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.retriever,
            memory=self.memory,
            verbose=True
        )
    
    def chat(self, question: str) -> str:
        result = self.chain({"question": question})
        return result["answer"]

# ä½¿ç”¨
rag = LangChainRAG("./knowledge")
print(rag.chat("FastAPIæ˜¯ä»€ä¹ˆï¼Ÿ"))
print(rag.chat("å®ƒå’ŒDjangoæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"))  # ä¼šè®°ä½ä¸Šä¸‹æ–‡
```

---

## ğŸ“º æ¨èBç«™è§†é¢‘

æœç´¢ï¼š
- **"LangChain RAG æ•™ç¨‹"**
- **"LangChain æ··åˆæ£€ç´¢"**
- **"LCEL è¡¨è¾¾å¼è¯­è¨€"**

---

## 9. ç»§ç»­å­¦ä¹ 

ğŸ“Œ **Week 5 å­¦ä¹ é¡ºåº**ï¼š
1. âœ… æ··åˆæ£€ç´¢ï¼ˆåŸç”Ÿæˆ–LangChainï¼‰
2. â¡ï¸ é‡æ’åºæ¨¡å‹è¯¦è§£
3. â¡ï¸ ä¸Šä¸‹æ–‡å‹ç¼©æŠ€æœ¯
4. â¡ï¸ é«˜çº§RAG Pipeline

---

**LangChainè®©RAGå¼€å‘æ›´åŠ ç®€å•ï¼ğŸ’ª**
