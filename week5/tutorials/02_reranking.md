# ğŸ† é‡æ’åºæ¨¡å‹è¯¦è§£

> **å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡Rerankeré‡æ’åºæ¨¡å‹ï¼Œä¼˜åŒ–æ£€ç´¢ç»“æœè´¨é‡

---

## 1. ä¸ºä»€ä¹ˆéœ€è¦é‡æ’åºï¼Ÿ

### é—®é¢˜ï¼šæ£€ç´¢â‰ æœ€ä½³æ’åº

```
æŸ¥è¯¢: "FastAPIæ€§èƒ½å¯¹æ¯”"

åˆæ­¥æ£€ç´¢ç»“æœï¼ˆTop-5ï¼‰:
1. "FastAPIæ¡†æ¶ä»‹ç»"          â† ç›¸å…³ä½†ä¸æ˜¯å¯¹æ¯”
2. "Python Webæ¡†æ¶å¯¹æ¯”"        â† ç›¸å…³
3. "FastAPI vs Djangoæ€§èƒ½æµ‹è¯•" â† æœ€ç›¸å…³ï¼ä¸ºä»€ä¹ˆæ’ç¬¬3ï¼Ÿ
4. "FastAPIå®‰è£…æ•™ç¨‹"          â† ä¸å¤ªç›¸å…³
5. "Web APIè®¾è®¡åŸåˆ™"          â† ä¸ç›¸å…³
```

### è§£å†³æ–¹æ¡ˆï¼šä¸¤é˜¶æ®µæ£€ç´¢

```
Stage 1: ç²—æ’ï¼ˆEmbeddingæ£€ç´¢ï¼‰
    â†“ æ£€ç´¢100ä¸ªå€™é€‰
Stage 2: ç²¾æ’ï¼ˆRerankeré‡æ’åºï¼‰
    â†“ é‡æ–°æ’åºï¼Œè¿”å›Top-5
```

---

## 2. RerankeråŸç†

### 2.1 Bi-Encoder vs Cross-Encoder

| ç±»å‹ | åŸç† | é€Ÿåº¦ | ç²¾åº¦ |
|------|------|------|------|
| Bi-Encoder | åˆ†åˆ«ç¼–ç queryå’Œdoc | å¿« | ä¸­ |
| Cross-Encoder | åŒæ—¶ç¼–ç query+doc | æ…¢ | é«˜ |

**Rerankerä½¿ç”¨Cross-Encoder**ï¼šå°†queryå’Œdocæ‹¼æ¥åä¸€èµ·ç¼–ç ï¼Œèƒ½æ•è·æ›´ç»†ç²’åº¦çš„äº¤äº’ã€‚

### 2.2 å·¥ä½œæµç¨‹

```python
# Bi-Encoder (Stage 1)
query_emb = encode(query)      # [0.1, 0.2, ...]
doc_emb = encode(doc)          # [0.3, 0.4, ...]
score = cosine_sim(query_emb, doc_emb)  # 0.85

# Cross-Encoder (Stage 2)
score = encode_pair(query, doc)  # ç›´æ¥è¾“å‡ºç›¸å…³æ€§åˆ†æ•° 0.92
```

---

## 3. ä½¿ç”¨sentence-transformersé‡æ’åº

### 3.1 å®‰è£…

```bash
pip install sentence-transformers
```

### 3.2 åŸºç¡€ä½¿ç”¨

```python
from sentence_transformers import CrossEncoder

# åŠ è½½æ¨¡å‹
model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

# è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
pairs = [
    ("FastAPIæ€§èƒ½å¯¹æ¯”", "FastAPI vs Djangoæ€§èƒ½æµ‹è¯•ï¼šFastAPIæ›´å¿«"),
    ("FastAPIæ€§èƒ½å¯¹æ¯”", "FastAPIå®‰è£…æ•™ç¨‹"),
    ("FastAPIæ€§èƒ½å¯¹æ¯”", "Python Webæ¡†æ¶ä»‹ç»"),
]

scores = model.predict(pairs)
for pair, score in zip(pairs, scores):
    print(f"{score:.4f}: {pair[1][:30]}")
```

è¾“å‡ºï¼š
```
0.9234: FastAPI vs Djangoæ€§èƒ½æµ‹è¯•ï¼šFastAPIæ›´å¿«
0.1245: FastAPIå®‰è£…æ•™ç¨‹
0.4532: Python Webæ¡†æ¶ä»‹ç»
```

---

## 4. ä½¿ç”¨BGE Rerankerï¼ˆä¸­æ–‡æ¨èï¼‰

### 4.1 å®‰è£…

```bash
pip install FlagEmbedding
```

### 4.2 ä½¿ç”¨

```python
from FlagEmbedding import FlagReranker

# åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä¼šä¸‹è½½ï¼‰
reranker = FlagReranker('BAAI/bge-reranker-base', use_fp16=True)

# é‡æ’åº
query = "FastAPIæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ"
documents = [
    "FastAPIæ˜¯åŸºäºStarletteçš„ç°ä»£Python Webæ¡†æ¶",
    "FastAPIæ€§èƒ½å“è¶Šï¼Œæ˜¯Pythonæœ€å¿«çš„Webæ¡†æ¶ä¹‹ä¸€",
    "Djangoæ˜¯ä¸€ä¸ªå…¨åŠŸèƒ½çš„Python Webæ¡†æ¶",
    "Flaskæ˜¯è½»é‡çº§Pythonå¾®æ¡†æ¶",
]

# è®¡ç®—åˆ†æ•°
pairs = [[query, doc] for doc in documents]
scores = reranker.compute_score(pairs)

# æ’åº
ranked = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)
for doc, score in ranked:
    print(f"[{score:.4f}] {doc}")
```

---

## 5. å®Œæ•´Rerankerç±»

```python
from sentence_transformers import CrossEncoder
from typing import Optional

class Reranker:
    def __init__(self, model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"):
        self.model = CrossEncoder(model_name)
    
    def rerank(
        self, 
        query: str, 
        documents: list[str], 
        top_k: Optional[int] = None
    ) -> list[dict]:
        """é‡æ’åºæ–‡æ¡£"""
        if not documents:
            return []
        
        # åˆ›å»ºquery-docå¯¹
        pairs = [(query, doc) for doc in documents]
        
        # è®¡ç®—åˆ†æ•°
        scores = self.model.predict(pairs)
        
        # æ’åº
        results = [
            {"document": doc, "score": float(score)}
            for doc, score in zip(documents, scores)
        ]
        results.sort(key=lambda x: x["score"], reverse=True)
        
        if top_k:
            results = results[:top_k]
        
        return results

# ä½¿ç”¨
reranker = Reranker()
results = reranker.rerank(
    query="Python Webæ¡†æ¶æ€§èƒ½",
    documents=["FastAPIå¾ˆå¿«", "DjangoåŠŸèƒ½å…¨", "Flaskå¾ˆè½»é‡"],
    top_k=2
)
```

---

## 6. é›†æˆåˆ°RAGç³»ç»Ÿ

```python
import chromadb
from openai import OpenAI
from sentence_transformers import CrossEncoder

class RAGWithReranker:
    def __init__(self):
        # å‘é‡æ•°æ®åº“
        self.chroma = chromadb.PersistentClient(path="./rerank_db")
        self.collection = self.chroma.get_or_create_collection("docs")
        
        # Reranker
        self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
        
        # LLM
        self.llm = OpenAI(
            api_key="your-key",
            base_url="https://api.deepseek.com/v1"
        )
    
    def add_documents(self, docs: list[str]):
        ids = [f"doc_{i}" for i in range(len(docs))]
        self.collection.upsert(documents=docs, ids=ids)
    
    def retrieve_and_rerank(
        self, 
        query: str, 
        initial_k: int = 20,
        final_k: int = 5
    ) -> list[str]:
        """ä¸¤é˜¶æ®µæ£€ç´¢"""
        # Stage 1: ç²—æ’
        results = self.collection.query(
            query_texts=[query],
            n_results=initial_k
        )
        candidates = results["documents"][0]
        
        # Stage 2: ç²¾æ’
        pairs = [(query, doc) for doc in candidates]
        scores = self.reranker.predict(pairs)
        
        # æ’åºå–Top-K
        ranked = sorted(
            zip(candidates, scores), 
            key=lambda x: x[1], 
            reverse=True
        )
        return [doc for doc, _ in ranked[:final_k]]
    
    def query(self, question: str) -> str:
        # æ£€ç´¢+é‡æ’åº
        docs = self.retrieve_and_rerank(question)
        
        if not docs:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
        
        # æ„å»ºPrompt
        context = "\n\n".join(docs)
        prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜ï¼š

æ–‡æ¡£ï¼š
{context}

é—®é¢˜ï¼š{question}

å›ç­”ï¼š"""
        
        # è°ƒç”¨LLM
        response = self.llm.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

# ä½¿ç”¨
rag = RAGWithReranker()
rag.add_documents([
    "FastAPIæ€§èƒ½æµ‹è¯•æ˜¾ç¤ºå…¶QPSå¯è¾¾åˆ°10000+ï¼Œæ¯”Djangoå¿«3å€",
    "FastAPIæ˜¯åŸºäºPythonçš„ç°ä»£Webæ¡†æ¶",
    "Djangoæ˜¯å…¨åŠŸèƒ½æ¡†æ¶ï¼Œé€‚åˆå¤§å‹é¡¹ç›®",
    "Flaské€‚åˆå°å‹é¡¹ç›®å’Œå¾®æœåŠ¡",
])

answer = rag.query("FastAPIçš„æ€§èƒ½æ€ä¹ˆæ ·ï¼Ÿ")
print(answer)
```

---

## 7. ä½¿ç”¨Cohere Rerank API

### 7.1 å®‰è£…

```bash
pip install cohere
```

### 7.2 ä½¿ç”¨

```python
import cohere

co = cohere.Client("your-cohere-api-key")

# é‡æ’åº
results = co.rerank(
    model="rerank-multilingual-v3.0",
    query="FastAPIæ€§èƒ½",
    documents=["FastAPIå¾ˆå¿«", "DjangoåŠŸèƒ½å…¨", "Flaskè½»é‡"],
    top_n=3
)

for item in results.results:
    print(f"[{item.relevance_score:.4f}] {item.document.text}")
```

---

## 8. å¸¸ç”¨Rerankeræ¨¡å‹

| æ¨¡å‹ | è¯­è¨€ | å¤§å° | æ¨èåœºæ™¯ |
|------|------|------|---------|
| ms-marco-MiniLM-L-6-v2 | è‹±æ–‡ | å° | å¼€å‘æµ‹è¯• |
| bge-reranker-base | ä¸­è‹± | ä¸­ | ä¸­æ–‡ç”Ÿäº§ |
| bge-reranker-large | ä¸­è‹± | å¤§ | é«˜ç²¾åº¦ |
| Cohere rerank-v3 | å¤šè¯­è¨€ | API | å•†ä¸šé¡¹ç›® |

---

## ğŸ“º æ¨èBç«™è§†é¢‘

æœç´¢ï¼š
- **"Reranker é‡æ’åº æ•™ç¨‹"**
- **"RAG ä¸¤é˜¶æ®µæ£€ç´¢"**
- **"BGE Reranker ä½¿ç”¨"**

---

## 9. ç»§ç»­å­¦ä¹ 

ğŸ“Œ **Week 5 å­¦ä¹ é¡ºåº**ï¼š
1. âœ… æ··åˆæ£€ç´¢
2. âœ… é‡æ’åºæ¨¡å‹è¯¦è§£ï¼ˆæœ¬æ•™ç¨‹ï¼‰
3. â¡ï¸ ä¸Šä¸‹æ–‡å‹ç¼©æŠ€æœ¯
4. â¡ï¸ é«˜çº§RAG Pipeline

---

**é‡æ’åºè®©æ£€ç´¢ç»“æœæ›´ç²¾å‡†ï¼ğŸ’ª**
