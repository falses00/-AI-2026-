# ğŸš€ Week 5 é¡¹ç›®ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

> **é¡¹ç›®ç›®æ ‡**ï¼šæ„å»ºä¸€ä¸ªä¼ä¸šçº§æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œæ•´åˆé«˜çº§RAGæŠ€æœ¯

---

## ğŸ¯ é¡¹ç›®è¦æ±‚

### åŠŸèƒ½éœ€æ±‚

1. **å¤šæºçŸ¥è¯†åº“**ï¼šæ”¯æŒFAQã€äº§å“æ–‡æ¡£ã€æ”¿ç­–æ–‡ä»¶
2. **æ··åˆæ£€ç´¢**ï¼šè¯­ä¹‰+å…³é”®è¯åŒé€šé“
3. **æ™ºèƒ½é‡æ’åº**ï¼šä½¿ç”¨Cross-Encoderç²¾æ’
4. **å¯¹è¯è®°å¿†**ï¼šæ”¯æŒå¤šè½®å¯¹è¯
5. **ç­”æ¡ˆè¯„ä¼°**ï¼šç½®ä¿¡åº¦è¯„ä¼°å’Œä¸ç¡®å®šæ€§æç¤º

### æŠ€æœ¯äº®ç‚¹

- æ··åˆæ£€ç´¢ + RRFèåˆ
- ä¸¤é˜¶æ®µæ£€ç´¢ï¼ˆç²—æ’+ç²¾æ’ï¼‰
- ä¸Šä¸‹æ–‡å‹ç¼©èŠ‚çœToken
- å¯¹è¯å†å²ç®¡ç†
- ç­”æ¡ˆç½®ä¿¡åº¦è¯„ä¼°

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
project_smart_cs/
â”œâ”€â”€ main.py                 # FastAPIå…¥å£
â”œâ”€â”€ config.py               # é…ç½®
â”œâ”€â”€ engines/
â”‚   â”œâ”€â”€ hybrid_retriever.py # æ··åˆæ£€ç´¢
â”‚   â”œâ”€â”€ reranker.py         # é‡æ’åº
â”‚   â”œâ”€â”€ compressor.py       # ä¸Šä¸‹æ–‡å‹ç¼©
â”‚   â””â”€â”€ rag_engine.py       # RAGå¼•æ“
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py          # æ•°æ®æ¨¡å‹
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ faq.json           # FAQæ•°æ®
â”‚   â””â”€â”€ docs/              # äº§å“æ–‡æ¡£
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ chat.html          # èŠå¤©ç•Œé¢
â””â”€â”€ requirements.txt
```

---

## ğŸ’» æ ¸å¿ƒä»£ç 

### config.py

```python
from pydantic_settings import BaseSettings
import os

class Settings(BaseSettings):
    DEEPSEEK_API_KEY: str = os.getenv("DEEPSEEK_API_KEY", "")
    DEEPSEEK_BASE_URL: str = "https://api.deepseek.com/v1"
    
    # æ£€ç´¢é…ç½®
    INITIAL_TOP_K: int = 20      # ç²—æ’æ•°é‡
    FINAL_TOP_K: int = 5         # ç²¾æ’æ•°é‡
    SEMANTIC_WEIGHT: float = 0.6 # è¯­ä¹‰æ£€ç´¢æƒé‡
    
    # å‹ç¼©é…ç½®
    MAX_CONTEXT_LENGTH: int = 2000
    
    # ç½®ä¿¡åº¦é˜ˆå€¼
    CONFIDENCE_THRESHOLD: float = 0.7

settings = Settings()
```

### engines/hybrid_retriever.py

```python
import chromadb
from rank_bm25 import BM25Okapi
import jieba
from typing import List, Dict
from config import settings

class HybridRetriever:
    def __init__(self, collection_name: str = "knowledge"):
        # ChromaDB
        self.chroma = chromadb.PersistentClient(path="./chroma_cs")
        self.collection = self.chroma.get_or_create_collection(collection_name)
        
        # BM25
        self.documents = []
        self.doc_ids = []
        self.bm25 = None
        
        # åŠ è½½å·²æœ‰æ–‡æ¡£
        self._load_existing()
    
    def _load_existing(self):
        """åŠ è½½å·²æœ‰æ–‡æ¡£åˆ°BM25"""
        if self.collection.count() > 0:
            results = self.collection.get()
            self.documents = results["documents"]
            self.doc_ids = results["ids"]
            tokenized = [list(jieba.cut(doc)) for doc in self.documents]
            self.bm25 = BM25Okapi(tokenized)
    
    def add_documents(self, docs: List[str], metadatas: List[Dict] = None):
        """æ·»åŠ æ–‡æ¡£"""
        start_id = len(self.doc_ids)
        new_ids = [f"doc_{start_id + i}" for i in range(len(docs))]
        
        # ChromaDB
        self.collection.upsert(
            documents=docs,
            ids=new_ids,
            metadatas=metadatas
        )
        
        # æ›´æ–°BM25
        self.documents.extend(docs)
        self.doc_ids.extend(new_ids)
        tokenized = [list(jieba.cut(doc)) for doc in self.documents]
        self.bm25 = BM25Okapi(tokenized)
    
    def search(self, query: str, top_k: int = 20) -> List[Dict]:
        """æ··åˆæ£€ç´¢"""
        # è¯­ä¹‰æ£€ç´¢
        semantic = self._semantic_search(query, top_k)
        
        # å…³é”®è¯æ£€ç´¢
        keyword = self._keyword_search(query, top_k) if self.bm25 else []
        
        # RRFèåˆ
        return self._rrf_fusion([semantic, keyword], top_k)
    
    def _semantic_search(self, query: str, top_k: int) -> List[tuple]:
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k,
            include=["documents", "distances"]
        )
        
        return [
            (results["documents"][0][i], 1 - results["distances"][0][i])
            for i in range(len(results["ids"][0]))
        ]
    
    def _keyword_search(self, query: str, top_k: int) -> List[tuple]:
        tokens = list(jieba.cut(query))
        scores = self.bm25.get_scores(tokens)
        
        if scores.max() > 0:
            scores = scores / scores.max()
        
        indices = scores.argsort()[-top_k:][::-1]
        return [(self.documents[i], scores[i]) for i in indices]
    
    def _rrf_fusion(self, result_lists: List[List[tuple]], top_k: int, k: int = 60) -> List[Dict]:
        scores = {}
        docs_map = {}
        
        for results in result_lists:
            for rank, (doc, score) in enumerate(results):
                if doc not in scores:
                    scores[doc] = 0
                    docs_map[doc] = doc
                scores[doc] += 1 / (k + rank + 1)
        
        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        return [
            {"content": doc, "score": score}
            for doc, score in sorted_docs[:top_k]
        ]
```

### engines/reranker.py

```python
from sentence_transformers import CrossEncoder
from typing import List, Dict

class Reranker:
    def __init__(self, model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"):
        self.model = CrossEncoder(model_name)
    
    def rerank(self, query: str, documents: List[Dict], top_k: int = 5) -> List[Dict]:
        """é‡æ’åºæ–‡æ¡£"""
        if not documents:
            return []
        
        contents = [d["content"] for d in documents]
        pairs = [(query, c) for c in contents]
        
        scores = self.model.predict(pairs)
        
        for i, doc in enumerate(documents):
            doc["rerank_score"] = float(scores[i])
        
        documents.sort(key=lambda x: x["rerank_score"], reverse=True)
        return documents[:top_k]
```

### engines/compressor.py

```python
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List

class ContextCompressor:
    def __init__(self):
        self.model = SentenceTransformer('BAAI/bge-small-zh-v1.5')
    
    def compress(self, query: str, documents: List[str], max_length: int = 2000) -> str:
        """å‹ç¼©ä¸Šä¸‹æ–‡"""
        # æ”¶é›†æ‰€æœ‰å¥å­
        all_sentences = []
        for doc in documents:
            sentences = [s.strip() for s in doc.replace('\n', 'ã€‚').split('ã€‚') if s.strip()]
            all_sentences.extend(sentences)
        
        if not all_sentences:
            return ""
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        query_emb = self.model.encode([query])
        sent_embs = self.model.encode(all_sentences)
        
        similarities = np.dot(sent_embs, query_emb.T).flatten()
        
        # é€‰æ‹©topå¥å­
        top_indices = similarities.argsort()[::-1]
        
        selected = []
        current_length = 0
        for i in top_indices:
            sent = all_sentences[i]
            if current_length + len(sent) > max_length:
                break
            selected.append((i, sent))
            current_length += len(sent)
        
        # æŒ‰åŸå§‹é¡ºåºæ’åˆ—
        selected.sort(key=lambda x: x[0])
        
        return 'ã€‚'.join([s for _, s in selected]) + 'ã€‚'
```

### engines/rag_engine.py

```python
from openai import OpenAI
from typing import Dict, List, Optional
from config import settings
from engines.hybrid_retriever import HybridRetriever
from engines.reranker import Reranker
from engines.compressor import ContextCompressor

class SmartCSEngine:
    def __init__(self):
        self.retriever = HybridRetriever()
        self.reranker = Reranker()
        self.compressor = ContextCompressor()
        
        self.llm = OpenAI(
            api_key=settings.DEEPSEEK_API_KEY,
            base_url=settings.DEEPSEEK_BASE_URL
        )
        
        self.conversation_history = {}
    
    def add_knowledge(self, documents: List[str], category: str = "general"):
        """æ·»åŠ çŸ¥è¯†"""
        metadatas = [{"category": category} for _ in documents]
        self.retriever.add_documents(documents, metadatas)
    
    def chat(self, session_id: str, question: str) -> Dict:
        """å¯¹è¯é—®ç­”"""
        # è·å–å¯¹è¯å†å²
        history = self.conversation_history.get(session_id, [])
        
        # 1. æ£€ç´¢ï¼ˆç²—æ’ï¼‰
        retrieved = self.retriever.search(question, top_k=settings.INITIAL_TOP_K)
        
        # 2. é‡æ’åºï¼ˆç²¾æ’ï¼‰
        reranked = self.reranker.rerank(question, retrieved, top_k=settings.FINAL_TOP_K)
        
        # 3. å‹ç¼©ä¸Šä¸‹æ–‡
        contents = [d["content"] for d in reranked]
        compressed = self.compressor.compress(
            question, contents, 
            max_length=settings.MAX_CONTEXT_LENGTH
        )
        
        # 4. è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(reranked)
        
        # 5. æ„å»ºPrompt
        history_text = self._format_history(history[-3:])  # æœ€è¿‘3è½®
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚

## å¯¹è¯å†å²
{history_text}

## å‚è€ƒèµ„æ–™
{compressed}

## ç”¨æˆ·é—®é¢˜
{question}

## å›ç­”è¦æ±‚
1. åªæ ¹æ®å‚è€ƒèµ„æ–™å›ç­”
2. å¦‚æœèµ„æ–™ä¸è¶³ï¼Œè¯šå®è¯´æ˜
3. è¯­æ°”å‹å¥½ä¸“ä¸š
4. ç®€æ´æ˜äº†

å›ç­”ï¼š"""
        
        # 6. ç”Ÿæˆå›ç­”
        response = self.llm.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        answer = response.choices[0].message.content
        
        # æ·»åŠ ä¸ç¡®å®šæ€§æç¤º
        if confidence < settings.CONFIDENCE_THRESHOLD:
            answer += "\n\nâš ï¸ æ¸©é¦¨æç¤ºï¼šä»¥ä¸Šä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œå¦‚éœ€è¿›ä¸€æ­¥å¸®åŠ©ï¼Œè¯·è”ç³»äººå·¥å®¢æœã€‚"
        
        # 7. æ›´æ–°å†å²
        history.append({"role": "user", "content": question})
        history.append({"role": "assistant", "content": answer})
        self.conversation_history[session_id] = history
        
        return {
            "answer": answer,
            "confidence": confidence,
            "sources_count": len(reranked),
            "context_length": len(compressed)
        }
    
    def _calculate_confidence(self, reranked: List[Dict]) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        if not reranked:
            return 0.0
        
        scores = [d.get("rerank_score", 0) for d in reranked]
        return min(1.0, max(0.0, sum(scores) / len(scores) + 0.3))
    
    def _format_history(self, history: List[Dict]) -> str:
        """æ ¼å¼åŒ–å†å²"""
        if not history:
            return "æ— "
        
        lines = []
        for h in history:
            role = "ç”¨æˆ·" if h["role"] == "user" else "å®¢æœ"
            lines.append(f"{role}: {h['content'][:100]}")
        
        return "\n".join(lines)
    
    def clear_session(self, session_id: str):
        """æ¸…é™¤ä¼šè¯"""
        if session_id in self.conversation_history:
            del self.conversation_history[session_id]
```

### main.py

```python
from fastapi import FastAPI, HTTPException
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
import uuid

from engines.rag_engine import SmartCSEngine

app = FastAPI(title="æ™ºèƒ½å®¢æœç³»ç»Ÿ")
engine = SmartCSEngine()

# åˆå§‹åŒ–ä¸€äº›FAQ
engine.add_knowledge([
    "Q: å¦‚ä½•é€€æ¬¾ï¼ŸA: ç™»å½•è´¦æˆ·ï¼Œè¿›å…¥è®¢å•é¡µé¢ï¼Œç‚¹å‡»é€€æ¬¾æŒ‰é’®å³å¯ç”³è¯·é€€æ¬¾ã€‚",
    "Q: é…é€éœ€è¦å¤šä¹…ï¼ŸA: æ™®é€šé…é€3-5å¤©ï¼ŒåŠ æ€¥é…é€1-2å¤©ã€‚",
    "Q: å¦‚ä½•ä¿®æ”¹è®¢å•ï¼ŸA: è®¢å•å‘è´§å‰å¯åœ¨è®¢å•è¯¦æƒ…é¡µä¿®æ”¹ï¼Œå‘è´§åè¯·è”ç³»å®¢æœã€‚",
    "Q: ä¼šå‘˜æœ‰ä»€ä¹ˆä¼˜æƒ ï¼ŸA: ä¼šå‘˜äº«å—95æŠ˜ä¼˜æƒ ï¼Œç§¯åˆ†ç¿»å€ï¼Œä¸“å±å®¢æœç­‰æƒç›Šã€‚",
    "Q: å¦‚ä½•è”ç³»å®¢æœï¼ŸA: å¯æ‹¨æ‰“400-xxx-xxxxæˆ–åœ¨çº¿ç•™è¨€ã€‚",
], category="faq")

class ChatRequest(BaseModel):
    session_id: str = None
    message: str

class ChatResponse(BaseModel):
    session_id: str
    answer: str
    confidence: float
    sources_count: int

@app.get("/", response_class=HTMLResponse)
async def index():
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>æ™ºèƒ½å®¢æœ</title>
        <style>
            body { font-family: Arial; max-width: 600px; margin: 50px auto; }
            .chat-box { height: 400px; overflow-y: auto; border: 1px solid #ddd; padding: 15px; border-radius: 8px; }
            .message { margin: 10px 0; padding: 10px; border-radius: 8px; }
            .user { background: #007bff; color: white; text-align: right; }
            .assistant { background: #f1f1f1; }
            .input-area { display: flex; margin-top: 15px; }
            .input-area input { flex: 1; padding: 10px; }
            .input-area button { padding: 10px 20px; background: #007bff; color: white; border: none; cursor: pointer; }
            .confidence { font-size: 0.8em; color: #666; }
        </style>
    </head>
    <body>
        <h1>ğŸ¤– æ™ºèƒ½å®¢æœ</h1>
        <div class="chat-box" id="chatBox"></div>
        <div class="input-area">
            <input type="text" id="messageInput" placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..." onkeypress="if(event.key==='Enter')sendMessage()">
            <button onclick="sendMessage()">å‘é€</button>
        </div>
        
        <script>
            let sessionId = null;
            
            function addMessage(content, isUser, confidence = null) {
                const box = document.getElementById('chatBox');
                let html = `<div class="message ${isUser ? 'user' : 'assistant'}">${content}`;
                if (confidence !== null) {
                    html += `<div class="confidence">ç½®ä¿¡åº¦: ${(confidence * 100).toFixed(0)}%</div>`;
                }
                html += '</div>';
                box.innerHTML += html;
                box.scrollTop = box.scrollHeight;
            }
            
            async function sendMessage() {
                const input = document.getElementById('messageInput');
                const message = input.value.trim();
                if (!message) return;
                
                addMessage(message, true);
                input.value = '';
                
                const res = await fetch('/chat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({session_id: sessionId, message})
                });
                
                const data = await res.json();
                sessionId = data.session_id;
                addMessage(data.answer, false, data.confidence);
            }
        </script>
    </body>
    </html>
    """

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    session_id = request.session_id or str(uuid.uuid4())
    
    result = engine.chat(session_id, request.message)
    
    return ChatResponse(
        session_id=session_id,
        answer=result["answer"],
        confidence=result["confidence"],
        sources_count=result["sources_count"]
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)
```

---

## ğŸš€ è¿è¡Œé¡¹ç›®

```bash
cd week5/projects/project_smart_cs
pip install -r requirements.txt
python main.py
```

è®¿é—® http://localhost:8002

---

## âœ… éªŒæ”¶æ ‡å‡†

- [ ] æ··åˆæ£€ç´¢æ­£å¸¸å·¥ä½œ
- [ ] é‡æ’åºæå‡ç»“æœè´¨é‡
- [ ] å¤šè½®å¯¹è¯è®°å¿†ä¸Šä¸‹æ–‡
- [ ] ç½®ä¿¡åº¦è¯„ä¼°åˆç†
- [ ] ä½ç½®ä¿¡åº¦æ—¶æœ‰æç¤º

---

## ğŸ”¥ è¿›é˜¶æŒ‘æˆ˜

1. æ·»åŠ æ„å›¾è¯†åˆ«
2. æ”¯æŒå·¥å•åˆ›å»º
3. é›†æˆçŸ¥è¯†å›¾è°±
4. æ·»åŠ ç®¡ç†åå°
