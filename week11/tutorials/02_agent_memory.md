# ğŸ’¾ Agentè®°å¿†ç³»ç»Ÿ

> **å­¦ä¹ ç›®æ ‡**ï¼šä¸ºAgentå®ç°çŸ­æœŸå’Œé•¿æœŸè®°å¿†ï¼Œæ”¯æŒä¸Šä¸‹æ–‡ç†è§£

---

## 1. è®°å¿†ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Agentè®°å¿†ç³»ç»Ÿæ¶æ„                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    çŸ­æœŸè®°å¿† (Working Memory)              â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚  â”‚
â”‚  â”‚  â”‚ å½“å‰å¯¹è¯    â”‚  â”‚ ä¼šè¯ä¸Šä¸‹æ–‡  â”‚  â”‚ ä¸´æ—¶å˜é‡    â”‚       â”‚  â”‚
â”‚  â”‚  â”‚ (æœ€è¿‘Nè½®)   â”‚  â”‚ (ç”¨æˆ·æ„å›¾)  â”‚  â”‚ (è®¡ç®—ç»“æœ)  â”‚       â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â”‚ é‡è¦ä¿¡æ¯æå–                      â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    é•¿æœŸè®°å¿† (Long-term Memory)            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚  â”‚
â”‚  â”‚  â”‚ ç”¨æˆ·ç”»åƒ    â”‚  â”‚ å†å²æ‘˜è¦    â”‚  â”‚ çŸ¥è¯†ç§¯ç´¯    â”‚       â”‚  â”‚
â”‚  â”‚  â”‚ (åå¥½/ä¹ æƒ¯) â”‚  â”‚ (é‡è¦äº‹ä»¶)  â”‚  â”‚ (å­¦åˆ°çš„)    â”‚       â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. çŸ­æœŸè®°å¿†å®ç°

### 2.1 æ»‘åŠ¨çª—å£è®°å¿†

```python
from collections import deque
from dataclasses import dataclass
from typing import Optional
import json

@dataclass
class Message:
    """æ¶ˆæ¯"""
    role: str
    content: str
    timestamp: str
    metadata: dict = None

class SlidingWindowMemory:
    """æ»‘åŠ¨çª—å£è®°å¿†"""
    
    def __init__(self, max_messages: int = 20, max_tokens: int = 4000):
        self.max_messages = max_messages
        self.max_tokens = max_tokens
        self.messages: deque = deque(maxlen=max_messages)
    
    def add(self, role: str, content: str, metadata: dict = None):
        """æ·»åŠ æ¶ˆæ¯"""
        self.messages.append(Message(
            role=role,
            content=content,
            timestamp=datetime.now().isoformat(),
            metadata=metadata
        ))
    
    def get_context(self, include_system: bool = True) -> list[dict]:
        """è·å–ä¸Šä¸‹æ–‡æ¶ˆæ¯"""
        context = []
        total_tokens = 0
        
        # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹ï¼Œç›´åˆ°è¾¾åˆ°tokené™åˆ¶
        for msg in reversed(self.messages):
            msg_tokens = len(msg.content) // 4  # ç²—ç•¥ä¼°è®¡
            if total_tokens + msg_tokens > self.max_tokens:
                break
            
            context.insert(0, {
                "role": msg.role,
                "content": msg.content
            })
            total_tokens += msg_tokens
        
        return context
    
    def clear(self):
        """æ¸…ç©ºè®°å¿†"""
        self.messages.clear()

# ä½¿ç”¨
memory = SlidingWindowMemory(max_messages=20)
memory.add("user", "ä½ å¥½")
memory.add("assistant", "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ")
context = memory.get_context()
```

### 2.2 å¸¦æ‘˜è¦çš„è®°å¿†

```python
from openai import OpenAI

class SummarizedMemory:
    """å¸¦æ‘˜è¦å‹ç¼©çš„è®°å¿†"""
    
    def __init__(self, recent_limit: int = 10, summary_threshold: int = 20):
        self.client = OpenAI()
        self.recent_limit = recent_limit
        self.summary_threshold = summary_threshold
        self.recent_messages: list = []
        self.summary: str = ""
    
    def add(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯"""
        self.recent_messages.append({"role": role, "content": content})
        
        # å¦‚æœæ¶ˆæ¯è¿‡å¤šï¼Œè¿›è¡Œæ‘˜è¦å‹ç¼©
        if len(self.recent_messages) > self.summary_threshold:
            self._compress()
    
    def _compress(self):
        """å‹ç¼©å†å²æ¶ˆæ¯ä¸ºæ‘˜è¦"""
        # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
        to_summarize = self.recent_messages[:-self.recent_limit]
        self.recent_messages = self.recent_messages[-self.recent_limit:]
        
        # ç”Ÿæˆæ‘˜è¦
        conversation_text = "\n".join([
            f"{m['role']}: {m['content']}" for m in to_summarize
        ])
        
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„å…³é”®ä¿¡æ¯ï¼Œä¿ç•™é‡è¦çš„äº‹å®å’Œç”¨æˆ·åå¥½ã€‚"},
                {"role": "user", "content": conversation_text}
            ]
        )
        
        new_summary = response.choices[0].message.content
        
        # åˆå¹¶æ–°æ—§æ‘˜è¦
        if self.summary:
            self.summary = f"{self.summary}\n\næœ€è¿‘è¡¥å……ï¼š{new_summary}"
        else:
            self.summary = new_summary
    
    def get_context(self) -> list[dict]:
        """è·å–å¸¦æ‘˜è¦çš„ä¸Šä¸‹æ–‡"""
        context = []
        
        if self.summary:
            context.append({
                "role": "system",
                "content": f"ä¹‹å‰å¯¹è¯æ‘˜è¦ï¼š\n{self.summary}"
            })
        
        context.extend(self.recent_messages)
        return context

# ä½¿ç”¨
memory = SummarizedMemory()
for i in range(30):
    memory.add("user", f"é—®é¢˜{i}")
    memory.add("assistant", f"å›ç­”{i}")
context = memory.get_context()
```

---

## 3. é•¿æœŸè®°å¿†å®ç°

### 3.1 ç”¨æˆ·ç”»åƒå­˜å‚¨

```python
from pydantic import BaseModel
from datetime import datetime

class UserProfile(BaseModel):
    """ç”¨æˆ·ç”»åƒ"""
    user_id: str
    name: str = ""
    preferences: dict = {}
    interaction_history: list = []
    learned_facts: list = []
    last_updated: datetime = None

class UserProfileStore:
    """ç”¨æˆ·ç”»åƒå­˜å‚¨"""
    
    def __init__(self, db_path: str = "user_profiles.json"):
        self.db_path = db_path
        self.profiles: dict[str, UserProfile] = {}
        self._load()
    
    def _load(self):
        """åŠ è½½æ•°æ®"""
        try:
            with open(self.db_path, 'r') as f:
                data = json.load(f)
                for user_id, profile_data in data.items():
                    self.profiles[user_id] = UserProfile(**profile_data)
        except FileNotFoundError:
            pass
    
    def _save(self):
        """ä¿å­˜æ•°æ®"""
        data = {uid: p.model_dump() for uid, p in self.profiles.items()}
        with open(self.db_path, 'w') as f:
            json.dump(data, f, default=str)
    
    def get_or_create(self, user_id: str) -> UserProfile:
        """è·å–æˆ–åˆ›å»ºç”¨æˆ·ç”»åƒ"""
        if user_id not in self.profiles:
            self.profiles[user_id] = UserProfile(user_id=user_id)
            self._save()
        return self.profiles[user_id]
    
    def update_preference(self, user_id: str, key: str, value):
        """æ›´æ–°ç”¨æˆ·åå¥½"""
        profile = self.get_or_create(user_id)
        profile.preferences[key] = value
        profile.last_updated = datetime.now()
        self._save()
    
    def add_learned_fact(self, user_id: str, fact: str):
        """æ·»åŠ å­¦ä¹ åˆ°çš„äº‹å®"""
        profile = self.get_or_create(user_id)
        if fact not in profile.learned_facts:
            profile.learned_facts.append(fact)
            self._save()

# ä½¿ç”¨
store = UserProfileStore()
store.update_preference("user123", "language", "zh-CN")
store.add_learned_fact("user123", "ç”¨æˆ·æ˜¯è½¯ä»¶å·¥ç¨‹å¸ˆ")
```

### 3.2 å‘é‡åŒ–é•¿æœŸè®°å¿†

```python
import chromadb
from openai import OpenAI

class VectorMemory:
    """å‘é‡åŒ–é•¿æœŸè®°å¿†"""
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.client = OpenAI()
        self.chroma = chromadb.Client()
        self.collection = self.chroma.get_or_create_collection(
            name=f"user_{user_id}_memory"
        )
    
    def store(self, content: str, memory_type: str = "general"):
        """å­˜å‚¨è®°å¿†"""
        # ç”ŸæˆåµŒå…¥
        response = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=content
        )
        embedding = response.data[0].embedding
        
        # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        memory_id = f"mem_{datetime.now().timestamp()}"
        self.collection.add(
            ids=[memory_id],
            embeddings=[embedding],
            documents=[content],
            metadatas=[{
                "type": memory_type,
                "timestamp": datetime.now().isoformat()
            }]
        )
    
    def recall(self, query: str, n_results: int = 5) -> list[str]:
        """å›å¿†ç›¸å…³è®°å¿†"""
        response = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=query
        )
        query_embedding = response.data[0].embedding
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results
        )
        
        return results["documents"][0] if results["documents"] else []

# ä½¿ç”¨
memory = VectorMemory("user123")
memory.store("ç”¨æˆ·å–œæ¬¢Pythonç¼–ç¨‹", "preference")
memory.store("ç”¨æˆ·æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ ", "context")

related = memory.recall("æ¨èä»€ä¹ˆç¼–ç¨‹é¡¹ç›®ï¼Ÿ")
print(related)  # ['ç”¨æˆ·å–œæ¬¢Pythonç¼–ç¨‹', 'ç”¨æˆ·æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ ']
```

---

## 4. ç»¼åˆè®°å¿†ç³»ç»Ÿ

```python
class AgentMemorySystem:
    """Agentç»¼åˆè®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.short_term = SummarizedMemory()
        self.long_term = VectorMemory(user_id)
        self.profile = UserProfileStore().get_or_create(user_id)
    
    def process_interaction(self, user_input: str, agent_response: str):
        """å¤„ç†äº¤äº’ï¼Œæ›´æ–°è®°å¿†"""
        # æ›´æ–°çŸ­æœŸè®°å¿†
        self.short_term.add("user", user_input)
        self.short_term.add("assistant", agent_response)
        
        # æå–å¹¶å­˜å‚¨é‡è¦ä¿¡æ¯åˆ°é•¿æœŸè®°å¿†
        important_info = self._extract_important_info(user_input, agent_response)
        if important_info:
            self.long_term.store(important_info)
    
    def _extract_important_info(self, user_input: str, response: str) -> str:
        """æå–é‡è¦ä¿¡æ¯"""
        # å¯ä»¥ç”¨LLMæå–å…³é”®ä¿¡æ¯
        client = OpenAI()
        result = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "æå–å¯¹è¯ä¸­å€¼å¾—é•¿æœŸè®°ä½çš„å…³é”®ä¿¡æ¯ã€‚å¦‚æœæ²¡æœ‰é‡è¦ä¿¡æ¯ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ã€‚"},
                {"role": "user", "content": f"ç”¨æˆ·: {user_input}\nAI: {response}"}
            ]
        )
        return result.choices[0].message.content.strip()
    
    def get_full_context(self, current_query: str) -> str:
        """è·å–å®Œæ•´ä¸Šä¸‹æ–‡"""
        # ç›¸å…³çš„é•¿æœŸè®°å¿†
        related_memories = self.long_term.recall(current_query, n_results=3)
        
        context = f"ç”¨æˆ·ä¿¡æ¯: {self.profile.name}, åå¥½: {self.profile.preferences}\n"
        
        if related_memories:
            context += f"ç›¸å…³è®°å¿†: {'; '.join(related_memories)}\n"
        
        return context

# ä½¿ç”¨
memory_system = AgentMemorySystem("user123")
memory_system.process_interaction(
    "æˆ‘æœ€è¿‘åœ¨å­¦ä¹ FastAPI",
    "å¤ªå¥½äº†ï¼FastAPIæ˜¯ä¸€ä¸ªå¾ˆæ£’çš„æ¡†æ¶..."
)
```

---

## 5. å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£çŸ­æœŸå’Œé•¿æœŸè®°å¿†çš„åŒºåˆ«
- [ ] èƒ½å¤Ÿå®ç°æ»‘åŠ¨çª—å£è®°å¿†
- [ ] ä¼šå®ç°å¸¦æ‘˜è¦å‹ç¼©çš„è®°å¿†
- [ ] èƒ½å¤Ÿæ„å»ºå‘é‡åŒ–é•¿æœŸè®°å¿†

---

## ç»§ç»­å­¦ä¹ 

ğŸ“Œ **Week 11 å­¦ä¹ é¡ºåº**ï¼š
1. âœ… ç”Ÿäº§çº§Agentæ¶æ„
2. âœ… Agentè®°å¿†ç³»ç»Ÿï¼ˆæœ¬æ•™ç¨‹ï¼‰
3. â¡ï¸ å¤šAgentåä½œ
